networks:
  data-engine-network:
    external: true

services:
  # ----------------------------------------------------
  # HADOOP (HDFS + YARN)
  # ----------------------------------------------------
  hadoop:
    container_name: hadoop
    build:
      context: .
      dockerfile: HadoopDockerfile
    hostname: hadoop
    stdin_open: true
    tty: true
    ports:
      - "9870:9870"   # NameNode UI
      - "9864:9864"   # DataNode UI
      - "9000:9000"   # HDFS
      - "8088:8088"   # YARN ResourceManager UI
    volumes:
      - ./hadoop/namenode:/data/hadoop-hadoop/dfs/name
      - ./hadoop/datanode:/data/hadoop-hadoop/dfs/data
    mem_limit: 6g
    cpus: 2
    networks:
      - data-engine-network

  # ----------------------------------------------------
  # SPARK (Driver submits to YARN)
  # ----------------------------------------------------
  spark:
    build:
      context: .
      dockerfile: SparkDockerfile
    container_name: spark
    command: ['sleep', 'infinity']
    depends_on:
      - hadoop
    environment:
      HADOOP_CONF_DIR: /opt/hadoop/etc/hadoop
      YARN_CONF_DIR: /opt/hadoop/etc/hadoop
      SPARK_CONF_DIR: /opt/spark/conf
    volumes:
      - ../../data/spark-jobs/:/opt/spark/jobs
    tty: true
    ports:
      - "4040:4040"   # Spark UI
      - "10000:10000" # thrift server
    networks:
      - data-engine-network

  # ----------------------------------------------------
  # JUPYTER (OPTIONAL, SAFE WAY)
  # ----------------------------------------------------
  jupyter:
    image: jupyter/pyspark-notebook:latest
    container_name: jupyter
    depends_on:
      - hadoop
    ports:
      - "8888:8888"
    environment:
      SPARK_MASTER: yarn
      HADOOP_CONF_DIR: /opt/hadoop/etc/hadoop
      YARN_CONF_DIR: /opt/hadoop/etc/hadoop
    volumes:
      - ./../../data/notebooks:/home/jovyan/work
    networks:
      - data-engine-network


# ----------------------------------------------------
# VOLUMES
# ----------------------------------------------------
volumes:
  hadoop_data:
